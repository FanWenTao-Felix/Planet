





## 请用1条sql语句通过下表查出以下结果。 game表：

 time         result
2018-07-27   负
2018-07-27   胜
2018-07-27   胜
2018-07-28   胜
2018-07-28   负

查询结果如下：

 时间          胜   负
2018-07-27    2    1
2018-07-28    1    1

```sql
select time as '时间', sum(case result when '胜' then 1 else 0 end) as ' 胜', sum(case result when '负' then 1 else 0 end) as '负' from game group by time;

```



## 有8个球，其中有1个重一点，其它的球都一样重，现在只有1个天平，怎么只称2次就找出那个重一点的球？

 称第一次：

随机取6个球出来，两边3个球放到天平上称。

称第二次：

若称第一次时天平显示两边一样重，那称剩下的2个球就能找出那个重一点的球了；

若天平显示一边重，那就从天平重的那边的3个球中随机取2个球放到天平上称，

如果天平显示一边重，那重的那边的那个球就是那个重一点的球，如果天平显示两边一样重，那剩下的没称的那个球就是那个重一点的球。





## 一条SQL语句执行得很慢的原因有哪些

[一条SQL语句执行得很慢的原因有哪些](https://mp.weixin.qq.com/s?__biz=Mzg2NzA4MTkxNQ==&mid=2247485346&idx=1&sn=22b36c3bdcca070adb2cac0ce3bc4ace&chksm=ce404c76f937c56018c4da7f0844357e3daeffb414def5dbc0cc8522dbed76f40b9e9577c805&scene=21#wechat_redirect)

一个 SQL 执行的很慢，我们要分两种情况讨论：

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

(2)、执行的时候，遇到锁，如表锁、行锁。

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

(2)、数据库选错了索引。



## 有了二叉查找树、平衡树为啥还需要红黑树？

[有了二叉查找树、平衡树为啥还需要红黑树](https://mp.weixin.qq.com/s?__biz=Mzg2NzA4MTkxNQ==&mid=2247485552&idx=1&sn=fc95ee79e55e5fcdbe64945521186095&chksm=ce4043a4f937cab227a48e17c5a6f44137acabe2b5644a76c715328e49d01d14adab380cc03f&scene=21#wechat_redirect)

虽然平衡树解决了二叉查找树退化为近似链表的缺点，能够把查找时间控制在 O(logn)，不过却不是最佳的，因为平衡树要求**每个节点的左子树和右子树的高度差至多等于1**，这个要求实在是太严了，导致每次进行插入/删除节点的时候，几乎都会破坏平衡树的第二个规则，



红黑树特点:

1、具有二叉查找树的特点。

2、根节点是黑色的；

3、每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存数据。

4、任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的。

5、每个节点，从该节点到达其可达的叶子节点是所有路径，都包含相同数目的黑色节点。

正是由于红黑树的这种特点，使得它能够在最坏情况下，也能在 O(logn) 的时间复杂度查找到某个节点。至于为什么就能够保证时间复杂度为 O(logn)，我这里就不细讲了，后面的文章可能会讲。



## 有一个一百万行的文件，内部是购买的商品ID，如何获取到购买最多的前一百个商品

思路：首先考察的肯定是大数据处理方案，这些数据肯定不能一次性读取到内存，那就需要拆分，将数据分隔处理。假设要分隔为 n 个文件。

•分隔：如果 ID 是整型的话，可以直接采用取模（id % n）的方式；如果 ID 是字符串可以先计算 hash 值然后再取模（hash(x) % n）的方式，将相同 ID 的商品分到同一个文件中。

•针对每个小文件进行 top100的排序，返回购买最多的100个商品 ID

•根据 n 个文件中的100个 ID，在进行一次排序，即可得到需要的数据。





## 设计秒杀系统

前端限流

包括按钮变灰, 或者 限制用户在x秒之内只能提交一次请求 如此限流，80%流量已拦。

用户维度

同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面 b



流量削峰

使用消息队列,   页面答题, 

随机返回

![img](https://youpaiyun.zongqilive.cn/image/5a34997e9d98cbcf10c4433efb2db3f0.png)



提前生成订单, 抢产品变成 抢订单

![](https://youpaiyun.zongqilive.cn/image/006tNc79ly1g3ydfd0grsj30l50jcmxh.jpg)



减库存问题

```sql
 //quantity为请求减掉的库存数量  
update s_store set amount = amount - quantity where amount>=quantity and postID = 1234
```





https://yq.aliyun.com/articles/618443



### 异步化处理的用户交互

系统设计成异步的，因此消费者不再是像以前一样同步地去等待反馈。消费者需要一个途径来获取抢购的状态和进度。我们的主体流程大体上分为几个阶段：

- 当等待人数大于 500 人，页面提示：排在您前面的人超过 500 位；
- 当等待人数小于等于 500 人，页面提示：您已挤进第 *** 位；
- 当等待时间大于等于 1 分钟，页面提示：剩余时间约 * 分钟。每次以分钟倒计时。
- 当等待时间小于 1 分钟，页面提示：预计剩余 * 秒。
- 抢购成功，后续跳转到订单支付页面

![](https://youpaiyun.zongqilive.cn/image/006tNc79ly1g3yebex0uej30ue0u0te7.jpg)



## 如何定位并优化慢查询sql

大致思路:

根据慢日志定位慢查询sql,

使用explain, 等工具分析sql,

修改sql或者尽量让sql走索引

![](https://youpaiyun.zongqilive.cn/image/006tNc79ly1g3uy8y96vjj31eq0n2ahe.jpg)



## 加密的方式

对称加密: 加密和解密都使用同一个密钥

非对称加密: 加密使用的密钥和解密使用的密钥不相同

哈希算法: 将任意长度的信息转换维固定长度的值, 算法不可逆

数字签名: 证明某个信息或者文件是某人发出/认同的



## 在浏览器地址栏键入URL, 按下回车之后经历的流程

- DNS解析
- TCP连接
- 发送HTTP请求
- 服务器处理请求并返回HTTP报文
- 浏览器解析渲染 页面
- 连接结束



## 介绍一下 hash，怎么解决冲突

这种转换是一种压缩映射，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。

  简单的说就是一种将任意长度的消息压缩到莫伊固定长度的消息摘要的函数。

### 拉链法

![](https://youpaiyun.zongqilive.cn/image/006tKfTcly1g0dyodg064j30f10co74m.jpg)

比如数组0的位置对应一个链表，链表有两个元素“496”和“896”，这说明元素“496”和“896”有着同样的Hash地址，这就是我们上边介绍的“冲突”或者“碰撞”。但是“链表数组”的存储方式很好地解决了Hash表中的冲突问题，发生冲突的元素会被存在一个对应Hash地址指向的链表中。实际上，“链表数组”就是一个指针数组，每一个指针指向一个链表的头结点，链表可能为空，也可能不为空。



设有一组关键字为(26，36，41，38，44，15，68，12，6，51)，用取余法构造散列函数，初始情况如下图所示：

![](https://youpaiyun.zongqilive.cn/image/006tKfTcly1g0dyqlcolgj30c308o3yh.jpg)

![](https://youpaiyun.zongqilive.cn/image/006tKfTcly1g0dyqracwvj30hs08oaa7.jpg)







## 给一个函数，返回 0 和 1，概率为 p 和 1-p，请你实现一个函数，使得返回 01 概率一样。

```c
int random_0_1()  
{  
    int i = RANDOM();  //假设给定的函数为RANDOM()
    int j = RANDOM();  
    int result;  
  
    while (true)  
    {  
        if (i == 0 && j == 1)  
        {  
            result = 0;  
            break;  
        }  
        else if (i == 1 && j == 0)  
        {  
            result = 1;  
            break;  
        }  
        else  
            continue;  
    }  
  
    return result;  
}  
```



## linux 用过的命令

cd mkdir  pwd, ls , tree, rm, touch, cat 
find, whereis, which,



## 10 亿个 url，每个 url 大小小于 56B，要求去重，内存 4G。

思路：

1.首先将给定的url调用hash方法计算出对应的hash的value，在10亿的url中相同url必然有着相同的value。

2.将文件的hash table 放到第value%n台机器上。

3.value/n是机器上hash table的值。

将文件的url进行hash，得到值value，相同的url的文件具有相同的value，所以会被分配到同一台机器v%n上。在同一台机器上的重复的url文件具有相同的value/n值，如果出现了冲突，不同的url在同一台机器上也可能有相同的value/n值。在每个机器上将value/n值作为key，url值作为value构成hash表进行去重。最后将内存中去重后的hash表中的value值即url写入磁盘。合并磁盘中的各部分url文件，完成去重。



## 如何只用2GB内存从20/40/80亿个整数中找到出现次数最多的数

分析:

一个 int 型占用 4B 的内存，所以哈希表的一条记录需要占用 8B，最坏的情况下，这 20 亿个数都是不同的数，大概会占用 16GB 的内存。

按上述方法的话，最多只能记录大概 2 亿多条不同的记录，2 亿多条不同的记录，大概是 1.6GB 的内存。

然而只有2G内存, 可以把这 20 亿个数映射到不同的文件中去，例如，数值在 0 至 2亿之间的存放在文件1中，数值在2亿至4亿之间的存放在文件2中….，由于 int 型整数大概有 42 亿个不同的数，所以我可以把他们映射到 21 个文件中去，如图:

![](https://youpaiyun.zongqilive.cn/image/006tNc79ly1g3o8olpssej30u008774f.jpg)

然后采用哈希表来统计，把这个数作为 key，把这个数出现的次数作为 value，之后我再遍历哈希表哪个数出现最多的次数最多就可以了

面试官：嗯，这个方法确实不错，不过，如果我给的这 20 亿个数数值比较集中的话，例如都处于 1~20000000 之间，那么你都会把他们全部映射到同一个文件中，你有优化思路吗？

小秋：那我可以先把每个数先做**哈希函数映射**，根据哈希函数得到的哈希值，再把他们存放到对应的文件中，如果哈希函数设计到好的话，那么这些数就会分布的比较平均。

### 40亿级别

面试官：那如果我把 20 亿个数加到 40 亿个数呢？

小秋：（这还不简单，映射到42个文件呗）那我可以加大文件的数量啊。

面试官：那如果我给的这 40 亿个数中数值都是一样的，那么你的哈希表中，某个 key 的 value 存放的数值就会是 40 亿，然而 int 的最大数值是 21 亿左右，那么就会出现溢出，你该怎么办？

小秋：（那我把 int 改为 long 不就得了，虽然会占用更多的内存，那我可以把文件分多几份呗，不过，这应该不是面试官想要的答案），我可以把 value 初始值赋值为 **负21亿**，这样，如果 value 的数值是 21 亿的话，就代表某个 key 出现了 42 亿次了。

### 80亿级别

面试官：反应挺快哈，那我如果把 40 亿增加到 80 亿呢？

小秋：（我靠，这变本加厉啊）………我知道了，我可以一边遍历一遍判断啊，如果我在统计的过程中，发现某个 key 出现的次数超过了 40 亿次，那么，就不可能再有另外一个 key 出现的次数比它多了，那我直接把这个 key 返回就搞定了。

## 判断一个数是否出现在这 40 亿个整数中

采用 bitmap 算法